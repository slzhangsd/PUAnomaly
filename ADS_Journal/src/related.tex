%!TEX root = ../cluster_semi.tex
\section{Related Work}
\label{sec:related}

Anomaly detection on the KPI stream deals with the task of recognizing unexpected data points from normal behavior.
Over the years, some traditional time series statistical algorithms Kalman Filtering~\cite{knorn2008adaptive}, Wavelet Analysis~\cite{lu2009network}, ARMA~\cite{pincombe2005anomaly}, Time Series Decomposition~\cite{chen2013provider}, Holt-Winters~\cite{yan2012argus}, \emph{etc.} are uesd for anomaly detection on KPI streams. These algorithms compute anomaly scores for data points based on simple statistical assumptions. In practice, experts need to choose effective algorithms and fine-tune algorithm's parameters for different type KPIs. Obviously, they suffer from the overhead of algorithm selection and parameter tuning.

Among the developed methods, supervised learning methods use operators' manual labels of KPI anomalies to learn (traditional statistical) algorithm selection and parameter tuning. To name some representative, EGADS~\cite{egads} separates forecasting, anomaly detection and alerting into three separate components and uses AdaBoost~\cite{freund1997decision} to select the most relevant anomalous data points. Opprentice~\cite{liu2015opprentice} ensembles 14 widely-used traditional statistical algorithms with 133 enumerated configurations of hyper-parameters for these algorithms to extract feature for the points. Then it trains classifier using Random Forest. However, manually \textbf{labeling anomalies} for millions of KPI streams is not feasible either.

Unsupervised learning has emerged as a promising field in KPI anomaly detection. Isolation Forest~\cite{liu2012isolation} assumes that the anomalous data points are few and different, then constructs tree structure to separate the points from the rest of points until all are isolated. The points closer to the root of the tree will be regared as anomaly points. It often suffers from low accuracy~\cite{zhang2018anomaly}.
DONUT~\cite{xu2018unsupervised}, which is based on VAE, a deep bayesian model performs superior in accuracy. This method focus on normal patterns instead of anomalies and try to learn the probability distribution of the normal data points. It often requires a long period (say six months) of training (KPI stream) data.

Semi-supervised learning~\cite{zhou2014semi} is halfway between supervised and unsupervised learning. These methods use unlabelled data to modify either parameters or models obtained from labeled data alone to maximize the learning performance of the models. ~\cite{sillito2008semi, ashfaq2017fuzziness, noto2012frac} use semi-supervised learning for anomaly detection, but are not designed for KPI streams (time series). In our \name{}, we utilize the semi-supervised learning to address the aforementioned challenges of anomlay detection on KPI stream.